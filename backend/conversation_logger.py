"""
Conversation Logger for University Assistant
Handles logging, analytics, and conversation history management
"""
import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

# Setup logging
logger = logging.getLogger(__name__)

class ConversationLogger:
    """
    Manages conversation logging, analytics and demo data generation
    """
    
    def __init__(self, log_dir: str = "./conversation_logs"):
        """
        Initialize conversation logger
        
        Args:
            log_dir (str): Directory to store conversation logs
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Create subdirectories
        (self.log_dir / "sessions").mkdir(exist_ok=True)
        (self.log_dir / "analytics").mkdir(exist_ok=True)
        (self.log_dir / "demos").mkdir(exist_ok=True)
        
        logger.info(f"Conversation logger initialized at: {self.log_dir}")
    
    def log_conversation(self, session_id: str, messages: List[Dict[str, Any]], 
                        metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Log to√†n b·ªô conversation c·ªßa m·ªôt session
        
        Args:
            session_id (str): ID c·ªßa session
            messages (List[Dict]): Danh s√°ch messages trong conversation
            metadata (Optional[Dict]): Th√¥ng tin metadata th√™m
            
        Returns:
            bool: True n·∫øu log th√†nh c√¥ng
        """
        try:
            # T·∫°o conversation data
            conversation_data = {
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "messages": messages,
                "stats": self._calculate_conversation_stats(messages),
                "metadata": metadata or {}
            }
            
            # L∆∞u file log theo session
            log_file = self.log_dir / "sessions" / f"{session_id}.json"
            
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"Logged conversation for session: {session_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error logging conversation: {e}")
            return False
    
    def log_message(self, session_id: str, message: Dict[str, Any]) -> bool:
        """
        Log m·ªôt message ƒë∆°n l·∫ª v√† append v√†o file session
        
        Args:
            session_id (str): ID c·ªßa session
            message (Dict): Message data
            
        Returns:
            bool: True n·∫øu log th√†nh c√¥ng
        """
        try:
            log_file = self.log_dir / "sessions" / f"{session_id}.json"
            
            # Load existing conversation ho·∫∑c t·∫°o m·ªõi
            if log_file.exists():
                with open(log_file, 'r', encoding='utf-8') as f:
                    conversation_data = json.load(f)
            else:
                conversation_data = {
                    "session_id": session_id,
                    "timestamp": datetime.now().isoformat(),
                    "messages": [],
                    "stats": {},
                    "metadata": {}
                }
            
            # Th√™m message m·ªõi
            conversation_data["messages"].append({
                **message,
                "timestamp": datetime.now().isoformat()
            })
            
            # C·∫≠p nh·∫≠t stats
            conversation_data["stats"] = self._calculate_conversation_stats(
                conversation_data["messages"]
            )
            conversation_data["last_updated"] = datetime.now().isoformat()
            
            # L∆∞u l·∫°i file
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            logger.error(f"Error logging message: {e}")
            return False
    
    def _calculate_conversation_stats(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        T√≠nh to√°n th·ªëng k√™ cho conversation
        
        Args:
            messages (List[Dict]): Danh s√°ch messages
            
        Returns:
            Dict: Conversation statistics
        """
        try:
            stats = {
                "total_messages": len(messages),
                "user_messages": 0,
                "bot_messages": 0,
                "avg_response_length": 0,
                "response_sources": {"faq": 0, "openai": 0, "function": 0},
                "message_types": {},
                "duration_minutes": 0
            }
            
            bot_response_lengths = []
            timestamps = []
            
            for msg in messages:
                role = msg.get("role", msg.get("sender", ""))
                
                if role in ["user"]:
                    stats["user_messages"] += 1
                elif role in ["assistant", "bot"]:
                    stats["bot_messages"] += 1
                    
                    # Track response length
                    content = msg.get("content", "")
                    if content:
                        bot_response_lengths.append(len(content))
                    
                    # Track response source
                    source = msg.get("source", "openai")
                    if source in stats["response_sources"]:
                        stats["response_sources"][source] += 1
                
                # Track message types
                msg_type = msg.get("type", "text")
                stats["message_types"][msg_type] = stats["message_types"].get(msg_type, 0) + 1
                
                # Collect timestamps
                timestamp_str = msg.get("timestamp", "")
                if timestamp_str:
                    try:
                        timestamps.append(datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')))
                    except:
                        pass
            
            # Calculate averages
            if bot_response_lengths:
                stats["avg_response_length"] = sum(bot_response_lengths) / len(bot_response_lengths)
            
            # Calculate conversation duration
            if len(timestamps) >= 2:
                duration = timestamps[-1] - timestamps[0]
                stats["duration_minutes"] = duration.total_seconds() / 60
            
            return stats
            
        except Exception as e:
            logger.error(f"Error calculating conversation stats: {e}")
            return {"error": str(e)}
    
    def get_session_analytics(self, days: int = 7) -> Dict[str, Any]:
        """
        L·∫•y analytics cho t·∫•t c·∫£ sessions trong kho·∫£ng th·ªùi gian
        
        Args:
            days (int): S·ªë ng√†y ƒë·ªÉ ph√¢n t√≠ch (t·ª´ h√¥m nay tr·ªü v·ªÅ tr∆∞·ªõc)
            
        Returns:
            Dict: Analytics data
        """
        try:
            sessions_dir = self.log_dir / "sessions"
            cutoff_date = datetime.now() - timedelta(days=days)
            
            analytics = {
                "period_days": days,
                "total_sessions": 0,
                "total_messages": 0,
                "total_users": 0,
                "avg_messages_per_session": 0,
                "response_sources": {"faq": 0, "openai": 0, "function": 0},
                "common_categories": {},
                "user_engagement": {
                    "short_sessions": 0,  # <= 3 messages
                    "medium_sessions": 0, # 4-10 messages
                    "long_sessions": 0    # > 10 messages
                },
                "peak_hours": {},
                "generated_at": datetime.now().isoformat()
            }
            
            session_files = list(sessions_dir.glob("*.json"))
            
            for session_file in session_files:
                try:
                    with open(session_file, 'r', encoding='utf-8') as f:
                        session_data = json.load(f)
                    
                    # Check if session is within time range
                    session_timestamp = datetime.fromisoformat(
                        session_data.get("timestamp", "").replace('Z', '+00:00')
                    )
                    
                    if session_timestamp < cutoff_date:
                        continue
                    
                    analytics["total_sessions"] += 1
                    
                    # Process session stats
                    stats = session_data.get("stats", {})
                    analytics["total_messages"] += stats.get("total_messages", 0)
                    
                    # Response sources
                    for source, count in stats.get("response_sources", {}).items():
                        analytics["response_sources"][source] += count
                    
                    # User engagement
                    msg_count = stats.get("total_messages", 0)
                    if msg_count <= 3:
                        analytics["user_engagement"]["short_sessions"] += 1
                    elif msg_count <= 10:
                        analytics["user_engagement"]["medium_sessions"] += 1
                    else:
                        analytics["user_engagement"]["long_sessions"] += 1
                    
                    # Peak hours analysis
                    for msg in session_data.get("messages", []):
                        timestamp_str = msg.get("timestamp", "")
                        if timestamp_str:
                            try:
                                dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                                hour = dt.hour
                                analytics["peak_hours"][hour] = analytics["peak_hours"].get(hour, 0) + 1
                            except:
                                pass
                
                except Exception as e:
                    logger.warning(f"Error processing session file {session_file}: {e}")
                    continue
            
            # Calculate averages
            if analytics["total_sessions"] > 0:
                analytics["avg_messages_per_session"] = analytics["total_messages"] / analytics["total_sessions"]
            
            analytics["total_users"] = analytics["total_sessions"]  # Assuming 1 session = 1 user for now
            
            # Save analytics
            analytics_file = self.log_dir / "analytics" / f"analytics_{datetime.now().strftime('%Y%m%d')}.json"
            with open(analytics_file, 'w', encoding='utf-8') as f:
                json.dump(analytics, f, ensure_ascii=False, indent=2)
            
            return analytics
            
        except Exception as e:
            logger.error(f"Error generating analytics: {e}")
            return {"error": str(e)}
    
    def create_demo_conversations(self) -> List[Dict[str, Any]]:
        """
        T·∫°o demo conversations ƒë·ªÉ demonstrate multi-turn interaction
        
        Returns:
            List[Dict]: Danh s√°ch demo conversations
        """
        try:
            demo_conversations = [
                {
                    "session_id": f"demo_session_1_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "title": "T∆∞ v·∫•n ƒëƒÉng k√Ω m√¥n h·ªçc",
                    "messages": [
                        {
                            "role": "user",
                            "content": "Ch√†o b·∫°n! T√¥i mu·ªën ƒëƒÉng k√Ω m√¥n Computer Science c∆° b·∫£n.",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant", 
                            "content": "Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ m√¥n CS101 - Introduction to Computer Science. ƒê√¢y l√† m√¥n c∆° b·∫£n v·ªõi 3 t√≠n ch·ªâ, do Dr. Smith gi·∫£ng d·∫°y v√†o Th·ª© 2, Th·ª© 4, Th·ª© 6 l√∫c 9:00-10:30 t·∫°i ph√≤ng Lab A.",
                            "source": "openai",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "user",
                            "content": "M√¥n n√†y c√≥ ƒëi·ªÅu ki·ªán ti√™n quy·∫øt kh√¥ng?",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "M√¥n CS101 kh√¥ng y√™u c·∫ßu ƒëi·ªÅu ki·ªán ti√™n quy·∫øt. ƒê√¢y l√† m√¥n d√†nh cho sinh vi√™n m·ªõi b·∫Øt ƒë·∫ßu h·ªçc l·∫≠p tr√¨nh. B·∫°n c√≥ mu·ªën bi·∫øt v·ªÅ l·ªãch thi ho·∫∑c h·ªçc ph√≠ kh√¥ng?",
                            "source": "function",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "user", 
                            "content": "V·∫≠y h·ªçc ph√≠ cho 3 t√≠n ch·ªâ n√†y bao nhi√™u?",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "üí∞ T√≠nh to√°n h·ªçc ph√≠:\nüìö S·ªë t√≠n ch·ªâ: 3\nüéì Lo·∫°i sinh vi√™n: Undergraduate\nüíµ H·ªçc ph√≠ c∆° b·∫£n: 4,500,000 VND\nüíµ Ph√≠ ƒëƒÉng k√Ω: 200,000 VND\nüíµ Ph√≠ th∆∞ vi·ªán: 100,000 VND\nüíµ Ph√≠ c√¥ng ngh·ªá: 150,000 VND\nüíµ T·ªîNG C·ªòNG: 4,950,000 VND",
                            "source": "function",
                            "timestamp": datetime.now().isoformat()
                        }
                    ]
                },
                {
                    "session_id": f"demo_session_2_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "title": "H·ªó tr·ª£ d·ªãch v·ª• th∆∞ vi·ªán",
                    "messages": [
                        {
                            "role": "user",
                            "content": "Th∆∞ vi·ªán m·ªü c·ª≠a m·∫•y gi·ªù?",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "Th∆∞ vi·ªán m·ªü c·ª≠a t·ª´ Th·ª© 2-Ch·ªß Nh·∫≠t: 7:00-22:00. B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªãch v·ª• h·ªçc t·∫≠p 24/7 t·∫°i khu v·ª±c t·ª± h·ªçc.",
                            "source": "faq",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "user",
                            "content": "T√¥i c·∫ßn m∆∞·ª£n s√°ch v·ªÅ AI v√† Machine Learning",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "üè¢ D·ªãch v·ª• sinh vi√™n:\n\nüîπ Th∆∞ vi·ªán\nüìù M√¥ t·∫£: D·ªãch v·ª• m∆∞·ª£n s√°ch, nghi√™n c·ª©u, v√† h·ªçc t·∫≠p\nüìç ƒê·ªãa ƒëi·ªÉm: T·∫ßng 1-3, T√≤a A\n‚è∞ Gi·ªù l√†m vi·ªác: Th·ª© 2-Ch·ªß Nh·∫≠t: 7:00-22:00\nüìß Li√™n h·ªá: library@university.edu.vn\n\nB·∫°n c√≥ th·ªÉ t√¨m s√°ch AI/ML ·ªü khu v·ª±c Computer Science t·∫ßng 2, ho·∫∑c li√™n h·ªá th·ªß th∆∞ ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t√¨m ki·∫øm c·ª• th·ªÉ.",
                            "source": "function",
                            "timestamp": datetime.now().isoformat()
                        }
                    ]
                },
                {
                    "session_id": f"demo_session_3_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "title": "Ki·ªÉm tra l·ªãch thi",
                    "messages": [
                        {
                            "role": "user",
                            "content": "Khi n√†o thi cu·ªëi k·ª≥ m√¥n Data Structures?",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "üìÖ L·ªãch thi:\n\nüìö M√¥n: CS201\nüìù Lo·∫°i thi: Final Exam\nüìÖ Ng√†y: 2024-05-25\n‚è∞ Gi·ªù: 14:00\nüè´ Ph√≤ng: Exam Room 1\n‚è±Ô∏è Th·ªùi gian: 120 ph√∫t\n\nB·∫°n nh·ªõ ƒë·∫øn s·ªõm 15 ph√∫t ƒë·ªÉ l√†m th·ªß t·ª•c nh√©!",
                            "source": "function",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "user",
                            "content": "C√≤n thi gi·ªØa k·ª≥ n·ªØa kh√¥ng?",
                            "timestamp": datetime.now().isoformat()
                        },
                        {
                            "role": "assistant",
                            "content": "üìÖ L·ªãch thi:\n\nüìö M√¥n: CS201\nüìù Lo·∫°i thi: Midterm Exam\nüìÖ Ng√†y: 2024-04-15\n‚è∞ Gi·ªù: 09:00\nüè´ Ph√≤ng: Room 301\n‚è±Ô∏è Th·ªùi gian: 90 ph√∫t\n\nThi gi·ªØa k·ª≥ ƒë√£ qua r·ªìi. B·∫°n c√≥ th·ªÉ t·∫≠p trung chu·∫©n b·ªã cho k·ª≥ thi cu·ªëi k·ª≥ v√†o 25/5 nh√©!",
                            "source": "function", 
                            "timestamp": datetime.now().isoformat()
                        }
                    ]
                }
            ]
            
            # L∆∞u demo conversations
            demos_dir = self.log_dir / "demos"
            demo_index = {
                "created_at": datetime.now().isoformat(),
                "total_demos": len(demo_conversations),
                "demos": []
            }
            
            for i, demo in enumerate(demo_conversations, 1):
                # T√≠nh stats cho demo
                demo["stats"] = self._calculate_conversation_stats(demo["messages"])
                
                # L∆∞u file demo
                demo_file = demos_dir / f"demo_{i}_{datetime.now().strftime('%Y%m%d')}.json"
                with open(demo_file, 'w', encoding='utf-8') as f:
                    json.dump(demo, f, ensure_ascii=False, indent=2)
                
                demo_index["demos"].append({
                    "id": i,
                    "title": demo["title"],
                    "session_id": demo["session_id"],
                    "file": demo_file.name,
                    "message_count": len(demo["messages"])
                })
            
            # L∆∞u demo index
            index_file = demos_dir / f"demo_index_{datetime.now().strftime('%Y%m%d')}.json"
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(demo_index, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Created {len(demo_conversations)} demo conversations")
            return demo_conversations
            
        except Exception as e:
            logger.error(f"Error creating demo conversations: {e}")
            return []
    
    def export_all_logs(self, output_file: Optional[str] = None) -> str:
        """
        Export t·∫•t c·∫£ logs ƒë·ªÉ backup ho·∫∑c analysis
        
        Args:
            output_file (Optional[str]): T√™n file output, n·∫øu None s·∫Ω auto generate
            
        Returns:
            str: Path c·ªßa file export
        """
        try:
            if not output_file:
                output_file = f"conversation_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            export_path = self.log_dir / output_file
            
            export_data = {
                "exported_at": datetime.now().isoformat(),
                "sessions": [],
                "analytics": self.get_session_analytics(30),  # 30 days
                "total_files": 0
            }
            
            # Collect all session files
            sessions_dir = self.log_dir / "sessions"
            for session_file in sessions_dir.glob("*.json"):
                try:
                    with open(session_file, 'r', encoding='utf-8') as f:
                        session_data = json.load(f)
                    export_data["sessions"].append(session_data)
                    export_data["total_files"] += 1
                except Exception as e:
                    logger.warning(f"Could not export session {session_file}: {e}")
            
            # Save export
            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Exported {export_data['total_files']} sessions to {export_path}")
            return str(export_path)
            
        except Exception as e:
            logger.error(f"Error exporting logs: {e}")
            return ""

# Singleton instance
_conversation_logger = None

def get_conversation_logger() -> ConversationLogger:
    """Get singleton conversation logger instance"""
    global _conversation_logger
    if _conversation_logger is None:
        _conversation_logger = ConversationLogger()
    return _conversation_logger
